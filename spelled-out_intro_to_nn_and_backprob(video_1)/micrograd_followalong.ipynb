{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071066904050358\n",
      "----------\n",
      "x2 0.5000001283844369\n",
      "w2 0.0\n",
      "x1 -1.5000003851533106\n",
      "w1 1.0000002567688737\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x1 = torch.Tensor([2.0]).double()\n",
    "x1.requires_grad = True\n",
    "x2 = torch.Tensor([0.0]).double()\n",
    "x2.requires_grad = True\n",
    "w1 = torch.Tensor([-3.0]).double()\n",
    "w1.requires_grad = True\n",
    "w2 = torch.Tensor([1.0]).double()\n",
    "w2.requires_grad = True\n",
    "b = torch.Tensor([6.8813735870195432]).double()\n",
    "b.requires_grad = True\n",
    "n = x1*w1 + x2*w2 + b\n",
    "o = torch.tanh(n)\n",
    "\n",
    "print(o.data.item())\n",
    "o.backward()\n",
    "\n",
    "print(\"-\"*10)\n",
    "print(\"x2\", x2.grad.item())\n",
    "print(\"w2\", w2.grad.item())\n",
    "print(\"x1\", x1.grad.item())\n",
    "print(\"w1\", w1.grad.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def trace(root):\n",
    "  # builds a set of all nodes and edges in a graph\n",
    "  nodes, edges = set(), set()\n",
    "  def build(v):\n",
    "    if v not in nodes:\n",
    "      nodes.add(v)\n",
    "      for child in v.prev:\n",
    "        edges.add((child, v))\n",
    "        build(child)\n",
    "  build(root)\n",
    "  return nodes, edges\n",
    "\n",
    "def draw_dot(root):\n",
    "  dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'}) # LR = left to right\n",
    "  \n",
    "  nodes, edges = trace(root)\n",
    "  for n in nodes:\n",
    "    uid = str(id(n))\n",
    "    # for any value in the graph, create a rectangular ('record') node for it\n",
    "    dot.node(name = uid, label = \"{ %s | data %.4f | grad %.4f }\" % (n.label, n.data, n.grad), shape='record')\n",
    "    if n.op:\n",
    "      # if this value is a result of some operation, create an op node for it\n",
    "      dot.node(name = uid + n.op, label = n.op)\n",
    "      # and connect this node to it\n",
    "      dot.edge(uid + n.op, uid)\n",
    "\n",
    "  for n1, n2 in edges:\n",
    "    # connect n1 to the op node of n2\n",
    "    dot.edge(str(id(n1)), str(id(n2)) + n2.op)\n",
    "\n",
    "  return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "    def __init__(self, data, __children=(), op=\"\", label=\"\"):\n",
    "        self.data = data\n",
    "        self.grad = 0.0\n",
    "        self.backward = lambda: None\n",
    "        self.prev = set(__children)\n",
    "        self.op = op\n",
    "        self.label = label\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Value=(data={self.data})\"\n",
    "\n",
    "    def __add__(self, other):\n",
    "        if type(other) != Value:\n",
    "            raise ValueError(f\"Other is not of type 'Value', other is of type '{type(other)}'\")\n",
    "\n",
    "        out = Value(self.data + other.data, (self, other), '+', label=\"v\")\n",
    "\n",
    "        def backward():\n",
    "            self.grad += out.grad\n",
    "            other.grad += out.grad\n",
    "        \n",
    "        out.backward = backward\n",
    "        return out\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        if type(other) != Value:\n",
    "            raise ValueError(f\"Other is not of type 'Value', other is of type '{type(other)}'\")\n",
    "    \n",
    "        out = Value(self.data - other.data, (self, other), '-', label=\"v\")\n",
    "\n",
    "        def backward():\n",
    "            self.grad += out.grad\n",
    "            other.grad += -out.grad\n",
    "        \n",
    "        out.backward = backward\n",
    "        return out\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        if type(other) != Value:\n",
    "            raise ValueError(f\"Other is not of type 'Value', other is of type '{type(other)}'\")\n",
    "\n",
    "        out = Value(self.data * other.data, (self, other), '*', label=\"v\")\n",
    "\n",
    "        def backward():\n",
    "            self.grad += other.data * out.grad\n",
    "            other.grad += self.data * out.grad\n",
    "        \n",
    "        out.backward = backward\n",
    "        return out\n",
    "    \n",
    "    def __pow__(self, other):\n",
    "        if type(other) != Value:\n",
    "            raise ValueError(f\"Other is not of type 'Value', other is of type '{type(other)}'\")\n",
    "\n",
    "        out = Value(self.data ** other.data, (self, other), \"**\", label=\"v\")\n",
    "\n",
    "        def backward():\n",
    "            self.grad += (other.data * self.data ** (other.data-1)) * out.grad\n",
    "        \n",
    "        out.backward = backward\n",
    "        return out\n",
    "\n",
    "    def tanh(self):\n",
    "        x = self.data\n",
    "        t = (math.exp(2*x) - 1) / (math.exp(2*x) + 1)\n",
    "        out = Value(t, (self,), \"tanh\", label=\"o\")\n",
    "\n",
    "        def backward():\n",
    "            self.grad += (1 - t**2) * out.grad\n",
    "        \n",
    "        out.backward = backward\n",
    "        return out\n",
    "    \n",
    "    def backwards(self):\n",
    "        self.grad = 1.0\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build_topo(node):\n",
    "            if node in visited:\n",
    "                return\n",
    "\n",
    "            visited.add(node)\n",
    "            for child in node.prev:\n",
    "                build_topo(child)\n",
    "\n",
    "            topo.append(node)\n",
    "        \n",
    "        build_topo(self)\n",
    "        for node in reversed(topo):\n",
    "            node.backward()\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, nin):\n",
    "        self.w = [Value(random.uniform(-1, 1), label=\"w\") for _ in range(nin)]\n",
    "        self.b = Value(random.uniform(-1, 1), label=\"b\")\n",
    "\n",
    "    def __call__(self, x):\n",
    "        out = sum((wi * xi for wi, xi in zip(self.w, x)), self.b)\n",
    "        return out.tanh()\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.w + [self.b]\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, nin, nout):\n",
    "        self.neurons = [Neuron(nin) for _ in range(nout)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        outs = [n(x) for n in self.neurons]\n",
    "        if len(outs) == 1:\n",
    "            return outs[0]\n",
    "\n",
    "        return outs\n",
    "    \n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        for neuron in self.neurons:\n",
    "            ps = neuron.parameters()\n",
    "            params.extend(ps)\n",
    "        \n",
    "        return params\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, nin, nouts):\n",
    "        sz = [nin] + nouts\n",
    "        self.layers = [Layer(sz[i], sz[i + 1]) for i in range(len(nouts))]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        for layer in self.layers:\n",
    "            ps = layer.parameters()\n",
    "            params.extend(ps)\n",
    "        \n",
    "        return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Init\n",
    "xs = [\n",
    "    [Value(2.0, label=\"i1\"), Value(3.0, label=\"i2\"), Value(-1.0, label=\"i3\")],\n",
    "    [Value(3.0, label=\"i1\"), Value(-1.0, label=\"i2\"), Value(0.5, label=\"i3\")],\n",
    "    [Value(0.5, label=\"i1\"), Value(1.0, label=\"i2\"), Value(1.0, label=\"i3\")],\n",
    "    [Value(1.0, label=\"i1\"), Value(1.0, label=\"i2\"), Value(-1.0, label=\"i3\")]\n",
    "]\n",
    "ys = [Value(1.0, label=\"o1\"), Value(-1.0, label=\"o2\"), Value(-1.0, label=\"o3\"), Value(1.0, label=\"o4\")]\n",
    "\n",
    "# Network Init\n",
    "nn = MLP(3, [4, 4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9.065074237785792\n",
      "1 8.16639801236619\n",
      "2 6.900970488365216\n",
      "3 5.392139518206354\n",
      "4 4.181512143008223\n",
      "5 3.6308872283459204\n",
      "6 3.3409548364965853\n",
      "7 3.104669739096446\n",
      "8 2.8758890517072637\n",
      "9 2.645003256085407\n",
      "10 2.4132804696285763\n",
      "11 2.1866727951502254\n",
      "12 1.9726542185166076\n",
      "13 1.777504494657832\n",
      "14 1.6045235773090425\n",
      "15 1.4538087458964426\n",
      "16 1.3232535033468613\n",
      "17 1.2098415239180142\n",
      "18 1.1105748184498725\n",
      "19 1.0229049809011905\n",
      "20 0.9448232958560516\n",
      "21 0.8747936013112828\n",
      "22 0.8116432088690656\n",
      "23 0.7544627370290532\n",
      "24 0.7025293073565473\n",
      "25 0.6552523241366797\n",
      "26 0.6121366822791764\n",
      "27 0.5727581857674094\n",
      "28 0.5367471231154791\n",
      "29 0.5037771656870509\n",
      "30 0.47355770362381866\n",
      "31 0.4458283949117831\n",
      "32 0.4203551411087467\n",
      "33 0.396926987654709\n",
      "34 0.37535363013019135\n",
      "35 0.35546332594860897\n",
      "36 0.3371010867978327\n",
      "37 0.32012707542006746\n",
      "38 0.3044151605620831\n",
      "39 0.2898516024018045\n",
      "40 0.2763338516396962\n",
      "41 0.2637694515359888\n",
      "42 0.25207503534582437\n",
      "43 0.2411754130785545\n",
      "44 0.23100274206602706\n",
      "45 0.22149577594709494\n",
      "46 0.21259918664050076\n",
      "47 0.2042629538350859\n",
      "48 0.1964418165444151\n",
      "49 0.18909478137505897\n",
      "50 0.1821846823413507\n",
      "51 0.17567778730985623\n",
      "52 0.16954344645553937\n",
      "53 0.1637537784403071\n",
      "54 0.15828339036738734\n",
      "55 0.1531091279089721\n",
      "56 0.14820985234017423\n",
      "57 0.14356624153275802\n",
      "58 0.13916061226298135\n",
      "59 0.13497676146665313\n",
      "60 0.1309998243301366\n",
      "61 0.12721614733842856\n",
      "62 0.12361317461132122\n",
      "63 0.12017934604713693\n",
      "64 0.11690400596206703\n",
      "65 0.11377732106330433\n",
      "66 0.11079020672758355\n",
      "67 0.10793426067501287\n",
      "68 0.10520170323275817\n",
      "69 0.10258532347565633\n",
      "70 0.100078430612516\n",
      "71 0.09767481005896207\n",
      "72 0.09536868370125738\n",
      "73 0.09315467391162029\n",
      "74 0.09102777092501435\n",
      "75 0.08898330323101405\n",
      "76 0.08701691067284878\n",
      "77 0.08512451997970538\n",
      "78 0.08330232248838812\n",
      "79 0.08154675383694962\n",
      "80 0.07985447543636666\n",
      "81 0.0782223575470894\n",
      "82 0.07664746380566909\n",
      "83 0.07512703706297208\n",
      "84 0.07365848640993207\n",
      "85 0.07223937527963314\n",
      "86 0.07086741052591897\n",
      "87 0.0695404323888666\n",
      "88 0.06825640526650253\n",
      "89 0.06701340922018198\n",
      "90 0.06580963214823864\n",
      "91 0.06464336256892325\n",
      "92 0.06351298295937897\n",
      "93 0.06241696360253311\n",
      "94 0.06135385689837085\n",
      "95 0.06032229210017913\n",
      "96 0.05932097044003635\n",
      "97 0.058348660611143466\n",
      "98 0.0574041945775725\n",
      "99 0.05648646368469195\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "for k in range(100):\n",
    "    # Forward Pass\n",
    "    ypreds = [nn(x) for x in xs]\n",
    "    loss = sum(((y - ypred)**Value(2.0) for y, ypred in zip(ys, ypreds)), Value(0.0))\n",
    "\n",
    "    for p in nn.parameters():\n",
    "        p.grad = 0.0\n",
    "    # Backawrd Pass\n",
    "    loss.backwards()\n",
    "\n",
    "    # Update\n",
    "    for p in nn.parameters():\n",
    "        p.data += -LEARNING_RATE * p.grad\n",
    "    \n",
    "    print(k, loss.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
